{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Write a function that processes a single .txt file. It must:\n",
    "* drop rows that do not contain a unique school identifier.\n",
    "* drop rows that correspond to elementary/middle school education. We are focusing on high school data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(textfilepath):\n",
    "    \"\"\"\n",
    "    Input: textfilepath, a path to the text file to be generated to a datafrmae\n",
    "    Output: Pandas DataFrame corresponding to input text file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(textfilepath, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016 = read_text_file(\"./txt_files/absenteeism_txt_files/2016-17_ChronAbsenteeism.txt\")\n",
    "df2017 = read_text_file(\"./txt_files/absenteeism_txt_files/2017-18_ChronAbsenteeism.txt\")\n",
    "df2018 = read_text_file(\"./txt_files/absenteeism_txt_files/2018-19_ChronAbsenteeism.txt\")\n",
    "#df2020 = read_text_file(\"./txt_files/absenteeism_txt_files/2020-21_ChronAbsenteeism.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(df):\n",
    "    \"\"\"\n",
    "    Input: Pandas DataFrame\n",
    "    Output: Pandas DataFrame with (a) rows with no school code and (b) rows corresponding to elementary/\n",
    "            middle school education removed\n",
    "    \"\"\"\n",
    "    rows_to_drop = []\n",
    "    #drop rows that do not have unique school code\n",
    "    for i, code in enumerate(df[\"SchoolCode\"]):\n",
    "        if pd.isnull(code) or code in [0,1]:\n",
    "            rows_to_drop.append(i)\n",
    "    #drop rows that correspond to elementary and middle school data\n",
    "    for i, reporting_category in enumerate(df[\"ReportingCategory\"]):\n",
    "        if reporting_category in [\"GRKN\", \"GRK\", \"GR13\", \"GR46\", \"GR78\", \"GRK8\", \"GR912\", \"GRUG\"]:\n",
    "            rows_to_drop.append(i)\n",
    "    df = df.drop(rows_to_drop,axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016 = drop_rows(df2016)\n",
    "df2017 = drop_rows(df2017)\n",
    "df2018 = drop_rows(df2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "We only want one row per school. As of now, the DataFrame has multiple rows per school to give metrics across different reporting groups.\n",
    "\n",
    "To do this, we will construct of matrix where rows are individual schools and columns are \n",
    "[\"RB\", \"RI\", \"RA\", \"RF\", \"RD\", \"RP\", \"RT\", \"RW\", \"GM\", \"GF\", \"GX\", \"GZ\", \"SE\", \"SD\", \"SS\", \"SM\", \"SF\", \"SH\", \"TA\"]\n",
    "\n",
    "These are each of the reporting categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_index_mapping(columns):\n",
    "    \"\"\"\n",
    "    Generates a mapping encoded as a dictionary where the keys are data columns (Absenteeism\n",
    "    Rates for different demographic groups) and values are numeric values/\n",
    "    Inputs:\n",
    "    columns: list of data columns (i.e. [\"RB\", \"RI\", etc.])\n",
    "    Outputs:\n",
    "    mapping: dictionary where keys are inputs columns and values are numeric encodings.\n",
    "             format: {\"RB\": 0, \"RI\": 1, etc}\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for i,col in enumerate(columns):\n",
    "        mapping[col] = i\n",
    "    return mapping\n",
    "mapping = generate_column_index_mapping([\"RB\", \"RI\", \"RA\", \"RF\", \"RH\", \"RD\", \"RP\", \"RT\", \"RW\", \"GM\", \"GF\", \"GX\", \"GZ\", \"SE\", \"SD\", \"SS\", \"SM\", \"SF\", \"SH\", \"TA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = [\"AcademicYear\", \"AggregateLevel\", \"CountyCode\", \"DistrictCode\", \"SchoolCode\", \"CountyName\",\n",
    "          \"DistrictName\", \"SchoolName\", \"CharterYN\", \"CAR_RB\", \"CAR_RI\", \"CAR_RA\", \"CAR_RF\", \"CAR_RH\", \"CAR_RD\",\n",
    "          \"CAR_RP\", \"CAR_RT\", \"CAR_RW\", \"CAR_GM\", \"CAR_GF\", \"CAR_GX\", \"CAR_GZ\", \"CAR_SE\", \"CAR_SD\", \"CAR_SS\",\n",
    "          \"CAR_SM\", \"CAR_SF\", \"CAR_SH\", \"CAR_TA\"]\n",
    "reporting_category_columns = [\"CAR_RB\", \"CAR_RI\", \"CAR_RA\", \"CAR_RF\", \"CAR_RH\", \"CAR_RD\",\n",
    "          \"CAR_RP\", \"CAR_RT\", \"CAR_RW\", \"CAR_GM\", \"CAR_GF\", \"CAR_GX\", \"CAR_GZ\", \"CAR_SE\", \"CAR_SD\", \"CAR_SS\",\n",
    "          \"CAR_SM\", \"CAR_SF\", \"CAR_SH\", \"CAR_TA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colapse_df(df):\n",
    "    \"\"\"\n",
    "    The input dataframe has many rows of data for a single school. For each school, there is \n",
    "    a separate row for each Chronic Absenteeism reporting group (i.e. one for female students,\n",
    "    one for white students, etc.) Using generate_column_index_mapping(columns), this function\n",
    "    groups all the data for one school into a single row and adds the columns \"CAR_RB\", \"CAR_RI\",\n",
    "    etc. to record the chronic absenteeism rates for each reporting category in a single row.\n",
    "    Input:\n",
    "    df: dataframe whose only preprocessing is done by drop_rows()\n",
    "    Output:\n",
    "    new_df: dataframe such that chronic absenteeism rates for each reporting group are added as\n",
    "            columns, and each school only has 1 row of data.\n",
    "    \"\"\"\n",
    "    #determine which rows are associated with each school\n",
    "    school_codes = df[\"SchoolCode\"].unique()\n",
    "    associated_rows = {}\n",
    "    for code in school_codes:\n",
    "        associated_rows[code] = []\n",
    "    for i in range(df.shape[0]):\n",
    "        #df[\"SchoolCode\"][df.index[i]] = school code at row i of df\n",
    "        associated_rows[df[\"SchoolCode\"][df.index[i]]].append(i)\n",
    "        \n",
    "    array = np.resize(np.array(all_columns), (1,len(all_columns))) #resize to stack rows with numpy\n",
    "    for code in school_codes:\n",
    "        rows = associated_rows[code] #get rows associated with code\n",
    "        firstrow = df.iloc[rows[0]] #use first row to capture redundant data\n",
    "        school_data = np.array([[firstrow[\"AcademicYear\"], firstrow[\"AggregateLevel\"], firstrow[\"CountyCode\"], \n",
    "                               firstrow[\"DistrictCode\"], firstrow[\"SchoolCode\"], firstrow[\"CountyName\"],\n",
    "                               firstrow[\"DistrictName\"], firstrow[\"SchoolName\"], firstrow[\"CharterYN\"],\n",
    "                                       None,None,None,None,None,None,None,None,None,None,None,None,None,\n",
    "                                       None,None,None,None,None,None,None]])\n",
    "        #note that all reporting categories data is initialized as None so we can determine what was missing\n",
    "        for row in rows:\n",
    "            #write reporting category data to correct column\n",
    "            school_data[0][9+mapping[df.iloc[row][\"ReportingCategory\"]]] = df.iloc[row][\"ChronicAbsenteeismRate\"]\n",
    "        array = np.append(array,school_data,axis=0) #stack rows\n",
    "    return pd.DataFrame(array[1:,:], columns=all_columns) #convert to df and return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2016 = colapse_df(df2016)\n",
    "new_df2017 = colapse_df(df2017)\n",
    "new_df2018 = colapse_df(df2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "Write a function that generates a single DataFrame given multiple dataframes from different time periods of the same category. The resultant DataFrame should organize each school's data in chronological order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we may be on different pages about what we were trying to produce in this step. I was thinking that it's organization would be as follows:\n",
    "\n",
    "row 1: school 1, year 1\n",
    "\n",
    "row 2: school 1, year 2\n",
    "\n",
    "row 3: school 1, year 3\n",
    "\n",
    "row 4: school 2, year 1\n",
    "\n",
    "row 5: school 2, year 2, and so on.\n",
    "\n",
    "I thought that there would be a different row per year, and we'd order the rows in the dataframe such that the schools data is grouped together and the rows are ordered chronologically. So I'm a little confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(dfs):\n",
    "    \"\"\"\n",
    "    Merges a list of multiple dataframes into a single dataframe that is ordered by school. \n",
    "    For example, if there are 3 years of data for school x, then these 3 rows will be immediately\n",
    "    in succession. \n",
    "    Input:\n",
    "    dfs: list of dataframes to be merged\n",
    "    Output:\n",
    "    master_df: merged dataframe that merges data from list of input dfs ordered by school\n",
    "    \"\"\"\n",
    "    #concatenate all dataframes in dfs along axis 0\n",
    "    master_df = pd.concat([df for df in dfs], axis=0, ignore_index=True)\n",
    "    \n",
    "    #generate zip of pairs of the format (row_index, school_code) for each row in master_df\n",
    "    #sort these pairs by school code\n",
    "    index_key = sorted(zip(master_df.index, master_df[\"SchoolCode\"]), key=lambda x: x[1])\n",
    "    \n",
    "    #extract the indices from the zipped pairs sorted by school code\n",
    "    #this will ensure that each schools data across multiple years appears in adjacent rows\n",
    "    sorted_indices = [item[0] for item in index_key]\n",
    "    return master_df.iloc[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge_dfs([new_df2016, new_df2017, new_df2018])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "We have some schools that are outside our target grade range (9-12), so we must drop all elementary and middle schools in our DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call read_text_file function on all public school types (2021)\n",
    "df_21schools = read_text_file(\"./txt_files/school_type_txt_files/pubschls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that do not have unique school name or code = 0\n",
    "misfitSchoolCodes = []\n",
    "for i, school in enumerate(df_21schools['School']):\n",
    "    if school  == 'No Data' or school == 0:\n",
    "        misfitSchoolCodes.append(i)\n",
    "df_21schools = df_21schools.drop(misfitSchoolCodes,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_little_ones(df, df_21schools):\n",
    "    \"\"\"\n",
    "    Uses data in df_21schools to drop schools from dataset that are elementary/middle schools.\n",
    "    Input:\n",
    "    df: merged dataframe \n",
    "    df_21schools: dataframe from ./txt_files/school_type_txt_files/pubschls.txt with rows that\n",
    "                  do not have unique school names dropped\n",
    "    Output:\n",
    "    df: dataframe with elementary/middle schools removed\n",
    "    \"\"\"\n",
    "    school_codes = []\n",
    "    for i in range(df_21schools.shape[0]):\n",
    "        #CDS code is a code that concatenates county, district, and school code. As per the \n",
    "        #CA Department of Education's documentation, the school code is the last 7 characters\n",
    "        #of this code\n",
    "        school_codes.append(int(str(df_21schools[\"CDSCode\"][i])[-7:]))\n",
    "    df_21schools[\"SchoolCode\"] = school_codes #insert a new column \"SchoolCode\" \n",
    "    \n",
    "    #generate zip of pairs of the format (row_index, school_code) for each row in df_21schools\n",
    "    #sort these pairs by school code\n",
    "    index_key = sorted(zip(df_21schools.index, df_21schools[\"SchoolCode\"]), key=lambda x: x[1])\n",
    "    sorted_indices = [item[0] for item in index_key]\n",
    "    df_21schools = df_21schools.iloc[sorted_indices]\n",
    "\n",
    "    #since school codes are sorted, all rows with school code = 0 will be dropped with this \n",
    "    #block of code\n",
    "    i = 0\n",
    "    rows_to_drop = []\n",
    "    while df_21schools[\"SchoolCode\"][df_21schools.index[i]] == 0:\n",
    "        rows_to_drop.append(df_21schools.index[i])\n",
    "        i += 1\n",
    "    df_21schools = df_21schools.drop(rows_to_drop,axis=0)\n",
    "    \n",
    "    #accumulate list of high_school_codes that are the school codes corresponding with \n",
    "    #schools that have \"EILCode\" = \"HS\"\n",
    "    high_school_codes = []\n",
    "    for i in range(df_21schools.shape[0]):\n",
    "        if df_21schools[\"EILCode\"][df_21schools.index[i]] == \"HS\":\n",
    "            high_school_codes.append(df_21schools[\"SchoolCode\"][df_21schools.index[i]])\n",
    "            \n",
    "    #drop all rows with school codes that are not in high_school_codes\n",
    "    little_schools = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df[\"SchoolCode\"][df.index[i]] not in high_school_codes:\n",
    "            little_schools.append(df.index[i])\n",
    "    \n",
    "    df = df.drop(little_schools,axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = drop_little_ones(millie_test_merge, df_21schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy final dataframe and save preprocessed data to .csv\n",
    "final_df1 = final_df.copy(deep=True)\n",
    "final_df1.reset_index()\n",
    "final_df1.to_csv(\"./preprocessed_data/2016-19ChronAbsenteeism.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1.to_csv(\"./preprocessed_data/2016-19ChronAbsenteeism.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
